{"cells":[{"cell_type":"markdown","id":"ac4a9a46","metadata":{"id":"ac4a9a46"},"source":["# Build recommendation system to recommend articles.\n"]},{"cell_type":"markdown","id":"cf2442c0","metadata":{"id":"cf2442c0"},"source":["# Objective: -\n","\n"]},{"cell_type":"markdown","id":"bb269461","metadata":{"id":"bb269461"},"source":["The goal of this challenge is to build recommendation system to recommend articles to their readers.\n"]},{"cell_type":"markdown","id":"996ba73a","metadata":{"id":"996ba73a"},"source":["# Dataset: -\n","\n","Many websites today use a recommendation system to recommend articles to their readers. For example, Most websites like Quora, LinkedIn, Medium are also using a recommendation system to recommend articles to its readers."]},{"cell_type":"markdown","id":"e3b60038","metadata":{"id":"e3b60038"},"source":["# Step 1: Import all the required libraries\n","\n","- __Pandas__ : In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis and storing in a proper way. In particular, it offers data structures and operations for manipulating numerical tables and time series\n","- __Sklearn__ : Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy. The library is built upon the SciPy (Scientific Python) that must be installed before you can use scikit-learn.\n","- __Pickle__ : Python pickle module is used for serializing and de-serializing a Python object structure. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script.\n","- __Seaborn__ : Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n","- __Matplotlib__ : Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK."]},{"cell_type":"code","execution_count":null,"id":"fc957303","metadata":{"id":"fc957303"},"outputs":[],"source":["#Loading libraries \n","import pandas as pd\n","from sklearn import preprocessing\n","import pickle\n","import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.feature_extraction import text\n","from sklearn.metrics.pairwise import cosine_similarity\n","import warnings\n","\n","\n","\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"1d0d47d5","metadata":{"id":"1d0d47d5"},"source":["# Step 2 : Read dataset and basic details of dataset\n","Goal:- In this step we are going to read the dataset, view the dataset and analysis the basic details like total number of rows and columns, what are the column data types and see to need to create new column or not.\n"]},{"cell_type":"markdown","id":"9d9e6568","metadata":{"id":"9d9e6568"},"source":["In this stage we are going to read our problem dataset and have a look on it."]},{"cell_type":"code","execution_count":null,"id":"da81da2c","metadata":{"id":"da81da2c","outputId":"26afa39a-ecf0-4f27-9328-b6c506059525"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data read done successfully...\n"]}],"source":["#loading the dataset\n","try:\n","    df = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/articles.csv\", encoding='latin1') #Path for the file\n","    print('Data read done successfully...')\n","except (FileNotFoundError, IOError):\n","    print(\"Wrong file or file path\") \n","    \n"]},{"cell_type":"code","execution_count":null,"id":"fdca2fc4","metadata":{"id":"fdca2fc4","outputId":"7b935e45-86da-4348-d1b7-b227e1f54241"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Article</th>\n","      <th>Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Data analysis is the process of inspecting and...</td>\n","      <td>Best Books to Learn Data Analysis</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The performance of a machine learning algorith...</td>\n","      <td>Assumptions of Machine Learning Algorithms</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You must have seen the news divided into categ...</td>\n","      <td>News Classification with Machine Learning</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>When there are only two classes in a classific...</td>\n","      <td>Multiclass Classification Algorithms in Machin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The Multinomial Naive Bayes is one of the vari...</td>\n","      <td>Multinomial Naive Bayes in Machine Learning</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             Article  \\\n","0  Data analysis is the process of inspecting and...   \n","1  The performance of a machine learning algorith...   \n","2  You must have seen the news divided into categ...   \n","3  When there are only two classes in a classific...   \n","4  The Multinomial Naive Bayes is one of the vari...   \n","\n","                                               Title  \n","0                  Best Books to Learn Data Analysis  \n","1         Assumptions of Machine Learning Algorithms  \n","2          News Classification with Machine Learning  \n","3  Multiclass Classification Algorithms in Machin...  \n","4        Multinomial Naive Bayes in Machine Learning  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# To view the content inside the dataset we can use the head() method that returns a specified number of rows, string from the top. \n","# The head() method returns the first 5 rows if a number is not specified.\n","df.head()"]},{"cell_type":"markdown","id":"530c0778","metadata":{"id":"530c0778"},"source":["After we read the data, we can look at the data using:"]},{"cell_type":"code","execution_count":null,"id":"1b66e1e0","metadata":{"id":"1b66e1e0","outputId":"8cacd3e4-8f8b-4548-e625-ac1912713e01"},"outputs":[{"name":"stdout","output_type":"stream","text":["The train data has 34 rows and 2 columns\n"]}],"source":["# count the total number of rows and columns.\n","print ('The train data has {0} rows and {1} columns'.format(df.shape[0],df.shape[1]))"]},{"cell_type":"code","execution_count":null,"id":"93672063","metadata":{"id":"93672063","outputId":"bff3b15b-a43e-4b42-dfa5-677557433a13"},"outputs":[{"data":{"text/plain":["(34, 2)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","id":"2646b822","metadata":{"id":"2646b822"},"source":["#### The df.shape method shows the shape of the dataset. "]},{"cell_type":"code","execution_count":null,"id":"98f3c269","metadata":{"id":"98f3c269","outputId":"e8d59f3a-1028-4916-d917-913ca8398b50"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 34 entries, 0 to 33\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   Article  34 non-null     object\n"," 1   Title    34 non-null     object\n","dtypes: object(2)\n","memory usage: 672.0+ bytes\n"]}],"source":["df.info()"]},{"cell_type":"markdown","id":"f4e190fe","metadata":{"id":"f4e190fe"},"source":["#### The df.info() method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage. "]},{"cell_type":"code","execution_count":null,"id":"c821b2c9","metadata":{"id":"c821b2c9","outputId":"60411ed1-e59e-4781-9c9d-91b671fa9555"},"outputs":[{"data":{"text/plain":["Article    The performance of a machine learning algorith...\n","Title             Assumptions of Machine Learning Algorithms\n","Name: 1, dtype: object"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df.iloc[1]"]},{"cell_type":"markdown","id":"a3bc946f","metadata":{"id":"a3bc946f"},"source":["####  df.iloc[ ] is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. The iloc property gets, or sets, the value(s) of the specified indexes."]},{"cell_type":"markdown","id":"950d90b8","metadata":{"id":"950d90b8"},"source":["### Data Type Check for every column"]},{"cell_type":"markdown","id":"QVXWeI2qjFGS","metadata":{"id":"QVXWeI2qjFGS"},"source":["**Why data type check is required?**"]},{"cell_type":"markdown","id":"abea9419","metadata":{"id":"abea9419"},"source":["Data type check helps us with understanding what type of variables our dataset contains. It helps us with identifying whether to keep that variable or not. If the dataset contains contiguous data, then only float and integer type variables will be beneficial and if we have to classify any value then categorical variables will be beneficial."]},{"cell_type":"code","execution_count":null,"id":"b0687ddf","metadata":{"id":"b0687ddf"},"outputs":[],"source":["objects_cols = ['object']\n","objects_lst = list(df.select_dtypes(include=objects_cols).columns)"]},{"cell_type":"code","execution_count":null,"id":"15f53da9","metadata":{"id":"15f53da9","outputId":"c027554e-14b5-491d-8fa5-7532146ef6f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of categorical columns are  2\n","There names are as follows:  ['Article', 'Title']\n"]}],"source":["print(\"Total number of categorical columns are \", len(objects_lst))\n","print(\"There names are as follows: \", objects_lst)"]},{"cell_type":"code","execution_count":null,"id":"c89abb20","metadata":{"id":"c89abb20"},"outputs":[],"source":["int64_cols = ['int64']\n","int64_lst = list(df.select_dtypes(include=int64_cols).columns)"]},{"cell_type":"code","execution_count":null,"id":"881ec45d","metadata":{"id":"881ec45d","outputId":"26ba29ba-7762-435a-9a57-c5499556ebc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of numerical columns are  0\n","There names are as follows:  []\n"]}],"source":["print(\"Total number of numerical columns are \", len(int64_lst))\n","print(\"There names are as follows: \", int64_lst)"]},{"cell_type":"code","execution_count":null,"id":"ed686600","metadata":{"id":"ed686600"},"outputs":[],"source":["float64_cols = ['float64']\n","float64_lst = list(df.select_dtypes(include=float64_cols).columns)"]},{"cell_type":"code","execution_count":null,"id":"5cc8245d","metadata":{"id":"5cc8245d","outputId":"642d7e52-4e24-423d-de42-e18b06e34e13"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of float64 columns are  0\n","There name are as follow:  []\n"]}],"source":["print(\"Total number of float64 columns are \", len(float64_lst))\n","print(\"There name are as follow: \", float64_lst)"]},{"cell_type":"markdown","id":"4eefdf2b","metadata":{"id":"4eefdf2b"},"source":["## Step 2 Insights: -"]},{"cell_type":"markdown","id":"9b15507a","metadata":{"id":"9b15507a"},"source":["1) We have total 2 features where 0 of them are float type, 2 are object type and 0 is int type.\n","\n"]},{"cell_type":"markdown","id":"d33952df","metadata":{"id":"d33952df"},"source":["# Step3: Data Preprocessing\n"]},{"cell_type":"markdown","id":"4218b6eb","metadata":{"id":"4218b6eb"},"source":["#### Why need of Data Preprocessing?\n","\n","Preprocessing data is an important step for data analysis. The following are some benefits of preprocessing data:\n","* It improves accuracy and reliability. Preprocessing data removes missing or inconsistent data values resulting from human or computer error, which can improve the accuracy and quality of a dataset, making it more reliable.\n","* It makes data consistent. When collecting data, it's possible to have data duplicates, and discarding them during preprocessing can ensure the data values for analysis are consistent, which helps produce accurate results.\n","* It increases the data's algorithm readability. Preprocessing enhances the data's quality and makes it easier for machine learning algorithms to read, use, and interpret it."]},{"cell_type":"markdown","id":"b30ea342","metadata":{"id":"b30ea342"},"source":["# Null and Nan values"]},{"cell_type":"markdown","id":"9a54fc9b","metadata":{"id":"9a54fc9b"},"source":["1. **Null Values**\n"]},{"cell_type":"markdown","id":"47947360","metadata":{"id":"47947360"},"source":["![missing-values.png](attachment:missing-values.png)"]},{"cell_type":"markdown","id":"e4e42282","metadata":{"id":"e4e42282"},"source":["A null value in a relational database is used when the value in a column is unknown or missing. A null is neither an empty string (for character or datetime data types) nor a zero value (for numeric data types)."]},{"cell_type":"code","execution_count":null,"id":"44699c6b","metadata":{"id":"44699c6b","outputId":"4b8c8c89-aafa-49ba-8e6c-5cc90dbf01c2"},"outputs":[{"data":{"text/plain":["Article    0\n","Title      0\n","dtype: int64"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","id":"ae58482d","metadata":{"id":"ae58482d"},"source":["As we notice that there are null values in our dataset.\n"]},{"cell_type":"markdown","id":"c6dd136e","metadata":{"id":"c6dd136e"},"source":["2. **Nan Values**"]},{"cell_type":"markdown","id":"9a2ac605","metadata":{"id":"9a2ac605"},"source":["![images.png](attachment:images.png)"]},{"cell_type":"markdown","id":"b069c2ac","metadata":{"id":"b069c2ac"},"source":["NaN, standing for Not a Number, is a member of a numeric data type that can be interpreted as a value that is undefined or unrepresentable, especially in floating-point arithmetic."]},{"cell_type":"code","execution_count":null,"id":"931bb432","metadata":{"id":"931bb432","outputId":"2b82f181-76b6-4c89-e10c-c348d809f374"},"outputs":[{"data":{"text/plain":["Article    0\n","Title      0\n","dtype: int64"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","id":"bdcf3aff","metadata":{"id":"bdcf3aff"},"source":["### As we notice that there are nan values in our dataset. "]},{"cell_type":"code","execution_count":null,"id":"a5ee28df","metadata":{"id":"a5ee28df"},"outputs":[],"source":["# We have many ways to fill Null/Nan Values as below:"]},{"cell_type":"markdown","id":"5b065689","metadata":{"id":"5b065689"},"source":["* mean -> average value (for numerical)\n","* mode -> most repeated value (for categorical)"]},{"cell_type":"markdown","id":"d8c22e57","metadata":{"id":"d8c22e57"},"source":["#### Another way to remove null and nan values is to use the method \"df.dropna(inplace=True)\". "]},{"cell_type":"markdown","id":"3e673103","metadata":{"id":"3e673103"},"source":["# Step 4: Imlementing Cosine Similarity and Creating Function to reccommend article to user"]},{"cell_type":"markdown","id":"3b4f8b7b","metadata":{"id":"3b4f8b7b"},"source":["To create an articles recommendation system, we need to focus on content rather than user interest. For example, if a user reads an article based on clustering, all recommended articles should also be based on clustering. So to recommend articles based on the content:\n","\n","* we need to understand the content of the article\n","* match the content with all the other articles\n","* and recommend the most suitable articles for the article that the reader is already reading\n","\n","For this task, we can use the concept of cosine similarity in machine learning. Cosine similarity is a method of building recommendation systems based on the content. It is used to find similarities between two different pieces of text documents. So we can use cosine similarity to build an article recommendation system.\n"]},{"cell_type":"markdown","id":"28ddfe81","metadata":{"id":"28ddfe81"},"source":["#### Tasks we are going to in this step:"]},{"cell_type":"markdown","id":"762da5d5","metadata":{"id":"762da5d5"},"source":["1. Impliment cosine similarity algorithm \n","2. Make a function for recommending article for a paticular article\n","3. Run function of recommending article for i times the articles in dataset"]},{"cell_type":"markdown","id":"0703cfa0","metadata":{"id":"0703cfa0"},"source":["### 1. Impliment cosine similarity algorithm"]},{"cell_type":"code","execution_count":null,"id":"ba1dc027","metadata":{"id":"ba1dc027"},"outputs":[],"source":["articles = df[\"Article\"].tolist()\n","uni_tfidf = text.TfidfVectorizer(input=articles, stop_words=\"english\")\n","uni_matrix = uni_tfidf.fit_transform(articles)\n","uni_sim = cosine_similarity(uni_matrix)\n"]},{"cell_type":"markdown","id":"74b07015","metadata":{"id":"74b07015"},"source":["### 2. Make a function for recommending article for a paticular article"]},{"cell_type":"code","execution_count":null,"id":"182c11c2","metadata":{"id":"182c11c2"},"outputs":[],"source":["def recommend_articles(x):\n","    return \", \".join(df[\"Title\"].loc[x.argsort()[-5:-1]])    \n"]},{"cell_type":"markdown","id":"0b8de348","metadata":{"id":"0b8de348"},"source":["### 3. Run function of recommending article for i times the articles"]},{"cell_type":"code","execution_count":null,"id":"b5067277","metadata":{"id":"b5067277","outputId":"51327500-8b03-4f9a-9ab7-154bb49f3b93"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Article</th>\n","      <th>Title</th>\n","      <th>Recommended Articles</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Data analysis is the process of inspecting and...</td>\n","      <td>Best Books to Learn Data Analysis</td>\n","      <td>Introduction to Recommendation Systems, Best B...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The performance of a machine learning algorith...</td>\n","      <td>Assumptions of Machine Learning Algorithms</td>\n","      <td>Applications of Deep Learning, Best Books to L...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You must have seen the news divided into categ...</td>\n","      <td>News Classification with Machine Learning</td>\n","      <td>Language Detection with Machine Learning, Appl...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>When there are only two classes in a classific...</td>\n","      <td>Multiclass Classification Algorithms in Machin...</td>\n","      <td>Assumptions of Machine Learning Algorithms, Be...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The Multinomial Naive Bayes is one of the vari...</td>\n","      <td>Multinomial Naive Bayes in Machine Learning</td>\n","      <td>Assumptions of Machine Learning Algorithms, Me...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             Article  \\\n","0  Data analysis is the process of inspecting and...   \n","1  The performance of a machine learning algorith...   \n","2  You must have seen the news divided into categ...   \n","3  When there are only two classes in a classific...   \n","4  The Multinomial Naive Bayes is one of the vari...   \n","\n","                                               Title  \\\n","0                  Best Books to Learn Data Analysis   \n","1         Assumptions of Machine Learning Algorithms   \n","2          News Classification with Machine Learning   \n","3  Multiclass Classification Algorithms in Machin...   \n","4        Multinomial Naive Bayes in Machine Learning   \n","\n","                                Recommended Articles  \n","0  Introduction to Recommendation Systems, Best B...  \n","1  Applications of Deep Learning, Best Books to L...  \n","2  Language Detection with Machine Learning, Appl...  \n","3  Assumptions of Machine Learning Algorithms, Be...  \n","4  Assumptions of Machine Learning Algorithms, Me...  "]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Recommended Articles\"] = [recommend_articles(x) for x in uni_sim]\n","df.head()"]},{"cell_type":"markdown","id":"dda1cbc0","metadata":{"id":"dda1cbc0"},"source":["As you can see from the output above, a new column has been added to the dataset that contains the titles of all the recommended articles. Now let’s see all the recommendations for an article:"]},{"cell_type":"code","execution_count":null,"id":"4d076170","metadata":{"id":"4d076170","outputId":"c659acce-b54a-451b-ba04-25f657d3d299"},"outputs":[{"name":"stdout","output_type":"stream","text":["BIRCH Clustering in Machine Learning, Clustering Algorithms in Machine Learning, DBSCAN Clustering in Machine Learning, K-Means Clustering in Machine Learning\n"]}],"source":["# lets check a a recommended article for a paticular article or index\n","print(df[\"Recommended Articles\"][22])"]},{"cell_type":"markdown","id":"505f15e7","metadata":{"id":"505f15e7"},"source":["Index 22 contains an article on “agglomerated clustering”, and all the recommended articles are also based on the concepts of clustering, so we can say that this recommender system can also give great results in real-time.\n","\n"]},{"cell_type":"markdown","id":"15c53205","metadata":{"id":"15c53205"},"source":["# Step 5: Save Model\n","**Goal:- In this step we are going to save our model in pickel format file.**"]},{"cell_type":"code","execution_count":null,"id":"e98dc16e","metadata":{"id":"e98dc16e"},"outputs":[],"source":["import pickle\n","pickle.dump(df, open('article_recommender_model.pkl', 'wb'))"]},{"cell_type":"code","execution_count":null,"id":"74e2bb00","metadata":{"id":"74e2bb00"},"outputs":[],"source":["import pickle \n","pickle.dump(uni_sim, open(\"Cosine_artciles.pkl\", 'wb'))"]},{"cell_type":"markdown","id":"a46d931d","metadata":{"id":"a46d931d"},"source":["# Step 6: After making model and checking its accuracy, we are going to deploy it in API/ Web App. "]},{"cell_type":"markdown","id":"e1d76588","metadata":{"id":"e1d76588"},"source":["This step holds a great importance as in this step we make a Web API which integrates our model and let it interacts with user.\n","The user simply put data he is asked to fill and our API will help in predicting."]},{"cell_type":"markdown","id":"d64a42a0","metadata":{"id":"d64a42a0"},"source":["### There are many methods to create Web Application like Flask, Streamlit, etc. We going to use streamlit to create API. Below is an API refrence. "]},{"cell_type":"markdown","source":["https://tinyurl.com/bdexnk6v"],"metadata":{"id":"LMkGHbIPn0NA"},"id":"LMkGHbIPn0NA"},{"cell_type":"markdown","id":"5c1aae78","metadata":{"id":"5c1aae78"},"source":["# Conclusion"]},{"cell_type":"markdown","id":"1ab4e800","metadata":{"id":"1ab4e800"},"source":["After observing the problem statement we have build an efficient model to overcome it. The above model helps in recommending articles to  their readers.  \n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}